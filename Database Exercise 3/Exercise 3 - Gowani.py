#!/usr/bin/env python
# coding: utf-8

# # Deliverables:
# 
# - Submit a single zip-compressed file that has the name: YourLastName_Exercise_1 that has the following files:
# 
#  1. Your **HTML document** that has your Source code and output
#  2. Your **ipynb script** that has your Source code and output
# 
# 
# # Objectives:
# 
# In this exercise, you will:
# 
#  - Perform data analysis tasks on data read from a CSV file and loaded into a DataFrame object
#  - Use SQLAlchemy load data stored in a DatFrame object into sqlite database engine
#  - Use SQLAlchemy to connect to sqlite database engine to execute  SQL  queries
# 
# 
# 
# 
# # Submission Formats :
# 
# Create a folder or directory with all supplementary files with your last name at the beginning of the folder name, compress that folder with zip compression, and post the zip-archived folder under the assignment link in Canvas. The following files should be included in an archive folder/directory that is uploaded as a single zip-compressed file. (Use zip, not StuffIt or any 7z or any other compression method.)
# 
# 
# 1. Complete IPYNB script that has the source code in Python used to access and analyze the data. The code should be submitted as an IPYNB script that can be loaded and run in Jupyter Notebook for Python
# 2. Output from the program, such as console listing/logs, text files, and graphics output for visualizations. If you use the Data Science Computing Cluster or School of Professional Studies database servers or systems, include Linux logs of your sessions as plain text files. Linux logs may be generated by using the script process at the beginning of your session, as demonstrated in tutorial handouts for the DSCC servers.
# 
# 
# Formatting Python Code
# When programming in Python, refer to Kenneth Reitz’ PEP 8: The Style Guide for Python Code:
# http://pep8.org/ (Links to an external site.)Links to an external site.
# There is the Google style guide for Python at
# https://google.github.io/styleguide/pyguide.html (Links to an external site.)Links to an external site.
# 
# **Comment often and in detail.**
# 

# In[1]:


import os

import  pickle

import pandas as pd  # panda's nickname is pd

import numpy as np  # numpy as np

from pandas import DataFrame, Series     # for convenience


# In[2]:


import os
os.getcwd()

xyzcust10=pd.read_csv('xyzcust10.csv')


# In[3]:


(xyzcust10).dtypes


# In[4]:


type(xyzcust10)


# In[5]:


pickle.dump(xyzcust10,open('xyzcust10.p','wb'))


# In[6]:


xyzcust10=pickle.load(open('xyzcust10.p','rb'))	

xyzcust10red = xyzcust10.copy()	# by default makes a “deep” copy

xyzcust10rev1=xyzcust10.copy()	# by default makes a “deep” copy


The above assumes that xyzcust10.p is in your default directory.  Otherwise, you'll need to include a path specification, of course.

xyzcust10 should be a pandas DataFrame:

# In[7]:


type(xyzcust10)


# In[8]:


xyzcust10.head()

xyzcust10 appears to have two nine-digit ZIP “supercode” columns with slightly different column labels or names.  To see them, try entering xyzcust10.columns or xyzcust10.dtypes at the command prompt.  Are the values in these two columns the same?  If so, we can get rid of one of them.  There are different ways we can figure out whether they are the same, but a simple way is to test each pair of values to see if they are equal or not, and then to total up the results, the number of equal pairs or not equal pairs:

# In[9]:


xyzcust10.columns


# In[10]:


xyzcust10.dtypes


# In[11]:


(xyzcust10.ZIP9_SUPERCODE!=xyzcust10.ZIP9_SUPERCODE).sum()

which will return zero if the values in the two columns are the same.  What result do you get?

Note that what's going on here is that what's in the parentheses is a logical test of inequality between the two columns of the DataFrame (which are also pandas Series objects), which results in a Series of true or false Boolean values.  The post-pended .sum() function adds up over the Series by treating the Trues as 1's, and the Falses as 0's.  So if the result is zero, the two Series are identical, except for their names, of course.



We could have also expressed the logical comparison in the parens as 
(~(xyzcust10.ZIP9_SUPERCODE==xyzcust10.ZIP9_SUPERCODE))

to get the same result, since the the “twidddle,” the ~, works in some pandas contexts as “not.”  What kind of result do you think you'd get with the following variation:

	~(xyzcust10.ZIP9_SUPERCODE==xyzcust10.ZIP9_SUPERCODE).sum()

Why might it be different?

Note that we could have referred to the columns differently, for example:

			xyzcust10['ZIP9_SUPERCODE']

Columns in DataFrames can be referred to in different ways.  We'll see more of them going forward.


# In[12]:


xyzcust10['ZIP9_SUPERCODE']

So, Oops!  Someone included the same column in the data twice, but with slightly different names. Why waste the space?  Why risk confusion?  Let's get rid of one of them:

We could do:

# In[13]:


del xyzcust10['ZIP9_SUPERCODE']
del xyzcust10rev1['ZIP9_SUPERCODE']

or
# In[14]:


xyzcust10red.drop('ZIP9_SUPERCODE',axis=1,inplace=True)

Next we're going to shift gears and gobble up some transaction data for XYZ's customers.  They are in a table in a SQLite3 relational database (“RDB”) file that's called xyz.db.  This file is available to you on Canvas.  At this point you might want to pickle xyzcust10rev1 in case you need to end your session and start again later.  Remember that things in a Python session are not permanent.

To make things simple you'll want to put the xyz.db file in a place where you can find it easily.  Your default directory would be a good bet.Remember what it is?  See what os.getcwd() tells you.
# In[15]:


# os.getcwd()

If you installed the sqlite3 client, you can take a look at this database (“DB”) using it and without using Python. sqlSQLite3 is a very simple and easy to use RDB, and it doesn't require a server.  Assuming that you've installed it and that you're in the directory were you put xyztrans.db, using the command from your OS command prompt:

c:\bader\nu\420\ExercisePractices\ExercisePractice3>sqlite3 xyz.db
SQLite version 3.8.8.3 2015-02-25 13:29:11
Enter ".help" for usage hints.
sqlite>

will start sqlite3 and open the db file.  You can see the tables in this db with the sqlite3 command .tables .  (That's a period, “.” before tables. “Help” in sqlSQLite3 is .help  .)

sqlite> .tables
xyztrans
sqlite> 
There are a couple of different ways to read and write data to RDBs using Python, but the most flexible and easiest may be by using what's in pandas.  pandas will make use of the SQLAlchemy package, which is available for installation within Canopy.  (Did you install it in Session 1?)  SQLAlchemy provides a consistent interface with different RDBs, SQLite being one of them.

Let's get SQLAlchemy into our IPython session:

# In[16]:


import sqlalchemy

Now if you do the sqlalchemy.<tab> trick from the command prompt, you'll be able to see SQLAlchemy's various (and many) attributes and functions.

To simplify things, let's get a function out of SQLAlchemy that we'll use to define the SQLite3 db we'll be working with:

# In[17]:


from sqlalchemy import create_engine

Now let's specify the xyz db as the SQLite3 RDB we want to work with:
# In[18]:


engine=create_engine('sqlite:///xyz.db')

This assumes that you have xyz.db in your current working directory.  There are different valid syntaxes, e.g.

sqlite:///:memory: (or, sqlite://) 
sqlite:///relative/path/to/file.db 
sqlite:////absolute/path/to/file.db 

We used the second syntax, above.  Be sure to use the correct number of slashes for the version you want to use.  You need the enclosing single quotes, too.
There's only one table in this RDB.  It's called “xyztrans.” Let's read it into a DataFrame:
# In[19]:


xyztrans=pd.read_sql('xyztrans', engine)

xyztrans is a DataFrame.  This defaults to reading all records from the db.  What columns have been read from the table xyztrans?  Try:
# In[20]:


xyztrans.dtypes

or
# In[21]:


xyztrans.columns

This db has only one table in it.  What if it had more than one, and you didn't know their names?  How would you know? Well, one way is to read some “metadata” from it:
# In[22]:


from sqlalchemy import schema


# In[23]:


xyzMetaData=schema.MetaData(bind=engine)
xyzMetaData.reflect()


# In[24]:


xyzMetaData.tables


xyzMetaData.tables will be a dict that contains information about the db.  Tables will be keys in this dict:

# In[25]:


xyzMetaData.tables.keys()


At this point there's only one table name, 'xyztrans,” in xyz.db.  You'll see another method for inspecting DB's below.

We're going to write the xyz customer records into a new table in the sqlite3 RDB, but before we do that let's make sure that the records are unique, that is, that no customer has more than one record.   We can do this with some pandas DataFrame methods.  Using the customer DataFrame xyzcust10rev1

# In[26]:


xyzcust10rev1.duplicated().sum()

will return a zero if all records are unique, or the number of rows in xyzcust10rev1 that are duplicates.  The reason is that the duplicated() method for the DataFrame returns a Series of Trues and Falses, a Boolean Series.  Summing over the Series forces the values to be cast as numeric.

Oops.  There are some duplicates.  How many duplicates do you find in xyzcust10rev1? 
To rid a DataFrame of unduplicated rows, 
# In[27]:


xyzcustUnDup=xyzcust10rev1.drop_duplicates()

xyzcustUnDup.duplicated().sum()


How many unique customer records do you now have?  By the way, note that you could have limited your examination to just one or more columns, for example just ACCTNO, customer account number, by providing ACCTNO as an argument or by using it to define a Series:

# In[28]:


xyzcust10rev1.duplicated('ACCTNO').sum()


# In[29]:


xyzcust10rev1.ACCTNO.duplicated().sum()


When there are duplicates of a record, which of them do you think .drop_duplicates() retains?

Now that we've checked for, and have removed, duplicate customer records, from the customer records, let's write them into a new table in xyztrans.db. 

# In[30]:


xyzcustUnDup.to_sql('xyzcust', engine)

Did it create the table in xyz.db?  Check:
# In[31]:


pd.read_sql_table('xyzcust', engine).columns

should produce the columns of the DataFrame you wrote to the db.  Remember that “engine” refers to the SQLite3 DB by way of defining the connection using SQLAlchemy's create_engine method.

How many tables are there now in xyz.db?  And, what are their names? Do

# In[32]:


xyzMetaData.tables.keys()

Another way to look at the metadata of an RDB using SQLAlchemy is by using the “inspect” method:
# In[33]:


xyzMetaData


# In[34]:


from sqlalchemy import inspect


# In[35]:


insp=inspect(engine)


# In[36]:


insp.get_table_names()


Do you think there are any duplicates in the order transaction data?  If so, what would you make of them?
You can use SQLAlchemy to query a DB so as to import selected records from an RDB.  You can also append records to existing tables in an RDB, create various kinds of DB indexes, and pretty much do everything you would do using standard SQL while interacting with an RDB using a client for it.   As a query example, suppose we wanted to select from the xyz tranaction data in the xyztrans.db all transactions made in XYZ's retail stores.  These are coded as RT in the table's TRAN_CHANNEL.  We could do:

# In[37]:


rttrans=pd.read_sql_query("SELECT * FROM xyztrans WHERE TRAN_CHANNEL='RT'", engine)



A last point about SQLAlchemy:  it has its own declarative language that provides means of interacting with DB's that is more “object oriented” than traditional SQL is.  You can find lots of documentation about SQLAlchemy at http://www.sqlalchemy.org.

# In[38]:


rttrans


# In[39]:


custtrans=pd.read_sql_query("SELECT * FROM xyzcust", engine)


# In[40]:


custtrans.head()


# In[41]:


allrttrans=pd.read_sql_query("SELECT * FROM xyztrans", engine)


# In[42]:


allrttrans.head()


# # Requirements :
# <font color='red'>**Note**: For number 1 and 2 below you need to query the database and display the results as a DataFrame. For number 3 you can query the database to get the number of records.</font>
# 1. Get a list of all records in xyzcust table where YTD_SALES_2009 > 1000. 

ytd_sales_over_1000 = pd.read_sql_query("SELECT * FROM xyzcust WHERE YTD_SALES_2009 > 1000 ORDER BY YTD_SALES_2009", engine)

ytd_sales_over_1000

import pandas_profiling
profile=pandas_profiling.ProfileReport(ytd_sales_over_1000)
profile.to_file("ytd_sales_over_1000.html")

# 2. Get a list of all records in xyzcust table where YTD_SALES_2009 > 1000 and CHANNEL_ACQUISITION = 'RT' 

ytd_sales_over_1000_cutsacq_rt = pd.read_sql_query("SELECT * FROM xyzcust WHERE YTD_SALES_2009 > 1000 AND CHANNEL_ACQUISITION = 'RT' ORDER BY YTD_SALES_2009", engine)

ytd_sales_over_1000_cutsacq_rt

# 3. What is the total number of records in in xyzcust table where YTD_SALES_2009 > 1000, CHANNEL_ACQUISITION = 'RT', and ZIP = 60056

ytd_sales_over_1000_cutsacq_rt_zip_60056 = pd.read_sql_query("SELECT COUNT(ZIP) FROM xyzcust WHERE YTD_SALES_2009 > 1000 AND CHANNEL_ACQUISITION = 'RT' AND ZIP = '60056'", engine)

ytd_sales_over_1000_cutsacq_rt_zip_60056

# 

# In[43]:


# Write your python code that meets the above requirements in these cells.


# In[ ]:





# In[ ]:





# In[ ]:




